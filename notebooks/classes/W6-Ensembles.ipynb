{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36352d1b",
   "metadata": {},
   "source": [
    "# Композиции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93c40d",
   "metadata": {},
   "source": [
    "## Bias-variance decomposition\n",
    "\n",
    "\n",
    "(на примере задачи регрессии)\n",
    "\n",
    "Задача: восстановить детерминированную функцию $f(x)$, если известные данные \n",
    "$$\n",
    "    y = f(x) + \\varepsilon,\n",
    "$$\n",
    "где $\\varepsilon$ случайный шум со свойствами \n",
    "$$\n",
    "    \\DeclareMathOperator{\\Var}{Var}\n",
    "    \\mathbb{E}\\varepsilon = 0\\text{ и } \\Var\\varepsilon = \\sigma^2. \n",
    "$$\n",
    "\n",
    "В качестве функции качества алгоритма $a$ разумно рассмотреть функцию\n",
    "$$\n",
    "    Q(a) = \\mathbb{E}_{x} \\mathbb{E}_{X, \\varepsilon} (y(x) - a(x, X))^2,\n",
    "$$\n",
    "где \n",
    "- $x$ — какая-то точка исходого пространства, \n",
    "- $X$ — случайная подвыборка пространства,\n",
    "- $a(x, X)$ — значние алгоритма $a$, обученного на выборке $X$, в точке $x$. \n",
    "\n",
    "\n",
    "Можно показать, что \n",
    "$$\n",
    "    \\DeclareMathOperator{\\bias}{bias}\n",
    "    Q(a) = \\mathbb{E}_x \\bias_X^2 a(x, X) + \\mathbb{E}_x \\Var_X [a(x, X)] + \\sigma^2,\n",
    "$$\n",
    "где\n",
    "- $\\bias_X a(x, X) = f(x) - \\mathbb{E}_X a(x, X)$ — **смещение алгоритма** в точке $x$, усредненное по всем подвыборкам $X$.\n",
    "\n",
    "- $\\Var_X [a(x, X)] = \\mathbb{E}_{X}[a(x, X) - \\mathbb{E}_X a(x, X)]^2$ — **разброс предсказаний алгоритма**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fdbe11",
   "metadata": {},
   "source": [
    "## Bagging\n",
    "Давайте выбирать случайные подвыборкии обучать одним и тем же методом, а затем усредним их предсказания.\n",
    "Заметим, что смещение при этом не измениться (в силу усреденения по всех подвыборкам там констаное слагаемое).\n",
    "\n",
    "Если полученные алгоримты нескореллированы, то разброс уменьшиться пропорционально числу алгоритов.\n",
    "$$\n",
    "\\Var (\\varphi + \\psi) = \\Var(\\varphi) + \\Var(\\psi) + 2\\mathbb{E}(\\varphi - \\mathbb{E}\\varphi)(\\psi - \\mathbb{E}\\psi).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c7584c",
   "metadata": {},
   "source": [
    "## Random Subspace Method\n",
    "Давайте случайно выбирать случайные подмножества признаков и обучать на них классифаторы.\n",
    "Это поможет снизить смещение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4281e",
   "metadata": {},
   "source": [
    "## Случайный лес\n",
    "Случаный лес = Bagging + RSM + Решающие деревья"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
